<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Debatts Demo Page</title>
  <script src="./static/tailwind.js"></script>
  <script src="./static/vue.global.js"></script>
  <script src="./static/flowbite.min.js"></script>
  <script src="./static/d3.v7.min.js"></script>
  <style type="text/tailwindcss">
    @tailwind base;
    @tailwind components;
    @tailwind utilities;

    @layer base {
      a[href^="http"] {
        @apply text-blue-500;
      }

      a:hover {
        @apply text-blue-700 underline;
      }

      h1 {
        @apply mb-6 text-4xl font-bold text-gray-900 dark:text-white text-center;
      }

      h4 {
        @apply mb-4 pt-12 text-3xl font-semibold text-gray-900 dark:text-white;
      }

      h5 {
        @apply mb-3 pt-4 text-2xl font-bold tracking-tight text-gray-900 dark:text-white;
      }

      p {
        @apply mb-4 font-normal text-gray-900 dark:text-gray-400 leading-relaxed;
      }
    }

    @layer components {
      .list-select {
        @apply block py-2 px-3 text-gray-900 rounded hover:bg-gray-100 md:hover:bg-transparent md:border-0 md:hover:text-blue-700 md:p-0 dark:text-white md:dark:hover:text-blue-500 dark:hover:bg-gray-700 dark:hover:text-white md:dark:hover:bg-transparent;
      }

      .tooltip {
        position: absolute;
        text-align: center;
        padding: 8px;
        font: 12px sans-serif;
        background: lightsteelblue;
        border: 0;
        border-radius: 8px;
        pointer-events: none;
        opacity: 0;
      }

      .text-p {
        @apply mb-4 font-normal text-gray-900 dark:text-gray-400 leading-relaxed;
      }

      .author {
        @apply font-medium mr-2 pb-1 text-gray-900 dark:text-gray-400 inline-block;
      }

      .affiliation {
        @apply font-medium mr-2 pb-1 text-gray-900 dark:text-gray-400 block;
      }
    }
  </style>
  <style>
    .center-text {
      text-align: center;
    }
  </style>

  <script>
    tailwind.config = {
      theme: {
        extend: {
          colors: {}
        }
      }
    }
  </script>
</head>

<body class="dark:bg-gray-900">
  <div id="app">

    <nav
      class="bg-white fixed w-full z-20 top-0 start-0 border-gray-200 dark:bg-gray-900 border-b border-gray-200 dark:border-gray-600">
      <div class="max-w-screen-xl flex flex-wrap items-center justify-between mx-auto p-3">
        <button data-collapse-toggle="navbar-default" type="button"
          class="inline-flex items-center p-2 w-10 h-10 justify-center text-sm text-gray-500 rounded-lg md:hidden hover:bg-gray-100 focus:outline-none focus:ring-2 focus:ring-gray-200 dark:text-gray-400 dark:hover:bg-gray-700 dark:focus:ring-gray-600"
          aria-controls="navbar-default" aria-expanded="false">
          <span class="sr-only">Open main menu</span>
          <svg class="w-5 h-5" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 17 14">
            <path stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2"
              d="M1 1h15M1 7h15M1 13h15" />
          </svg>
        </button>

        <div class="hidden w-full md:block md:w-auto ml-auto" id="navbar-default">
          <ul
            class="font-medium flex flex-col p-4 md:p-0 mt-4 border border-gray-100 rounded-lg bg-gray-50 md:flex-row md:space-x-8 rtl:space-x-reverse md:mt-0 md:border-0 md:bg-white dark:bg-gray-800 md:dark:bg-gray-900 dark:border-gray-700">
            <li>
              <a href="#home" class="list-select">Home</a>
            </li>
            <li>
              <a href="#dataset" class="list-select">Dataset</a>
            </li>
            <li>
              <a href="#pipeline" class="list-select">Pipeline</a>
            </li>
            </li>
            <a href="#model" class="list-select">Model</a>
            </li>
            <li>
              <a href="#demos" class="list-select">Demos</a>
            </li>
            <!-- <li>
              <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia" class="list-select" target="_blank">
                <svg class="w-6 h-6 text-gray-900 hover:text-blue-700" aria-hidden="true"
                  xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="currentColor" viewBox="0 0 24 24">
                  <path fill-rule="evenodd"
                    d="M12.006 2a9.847 9.847 0 0 0-6.484 2.44 10.32 10.32 0 0 0-3.393 6.17 10.48 10.48 0 0 0 1.317 6.955 10.045 10.045 0 0 0 5.4 4.418c.504.095.683-.223.683-.494 0-.245-.01-1.052-.014-1.908-2.78.62-3.366-1.21-3.366-1.21a2.711 2.711 0 0 0-1.11-1.5c-.907-.637.07-.621.07-.621.317.044.62.163.885.346.266.183.487.426.647.71.135.253.318.476.538.655a2.079 2.079 0 0 0 2.37.196c.045-.52.27-1.006.635-1.37-2.219-.259-4.554-1.138-4.554-5.07a4.022 4.022 0 0 1 1.031-2.75 3.77 3.77 0 0 1 .096-2.713s.839-.275 2.749 1.05a9.26 9.26 0 0 1 5.004 0c1.906-1.325 2.74-1.05 2.74-1.05.37.858.406 1.828.101 2.713a4.017 4.017 0 0 1 1.029 2.75c0 3.939-2.339 4.805-4.564 5.058a2.471 2.471 0 0 1 .679 1.897c0 1.372-.012 2.477-.012 2.814 0 .272.18.592.687.492a10.05 10.05 0 0 0 5.388-4.421 10.473 10.473 0 0 0 1.313-6.948 10.32 10.32 0 0 0-3.39-6.165A9.847 9.847 0 0 0 12.007 2Z"
                    clip-rule="evenodd" />
                </svg>    
              </a>
            </li> -->
            <li>
              <a href="https://huggingface.co/datasets/amphion/Debatts-Data" class="list-select" target="_blank">
                <img class="h-6 w-6" src="https://huggingface.co/front/assets/huggingface_logo-noborder.svg" />
              </a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <div class="p-5 md:p-0 mt-16 max-w-screen-xl mx-auto">
      <div class="p-6" id="home">

        <!-- <div class="mt-8 mb-8">
          <h1>Emilia: An Extensive, Multilingual, and Diverse Speech Dataset for Large-Scale Speech Generation</h1>
        </div> -->
        <div class="mt-8 mb-8">
          <h1>Debatts: Zero-Shot Debating Text-to-Speech Synthesis</h1>
        </div>

        <div class="center-text text-sm">
          <span class="author">Yiqiao Huang<sup>1</sup> </span>
          <span class="author">Yuancheng Wang<sup>1</sup> </span>
          <span class="author">Jiaqi Li<sup>1</sup> </span>
          <span class="author">Haotian Guo<sup>1</sup></span>
          <span class="author">Haorui He<sup>1</sup> </span>
          <span class="author">Zhizheng Wu<sup>1,‡</sup> </span>
          <span class="author">Shunsi Zhang<sup>2</sup> </span>
        </div>
        <div class="center-text text-sm">
          <span class="affiliation"><sup>1</sup> The Chinese University of Hong Kong, Shenzhen, China</span>
          <span class="affiliation"><sup>2</sup> Guangzhou Quwan Network Technology, Guangzhou, China</span>
        </div>
        <div class="center-text text-sm">
          <span class="author"><sup>‡</sup> Corresponding authors.</span>
        </div>
        <br>

        <!-- 添加各种链接 -->
        <!-- <div class="flex gap-2 justify-center flex-wrap">
          <a href="https://arxiv.org/abs/2407.05361" target="_blank">
            <img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg">
          </a>
          <a href="https://huggingface.co/datasets/amphion/Emilia-Dataset" target="_blank">
            <img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow">
          </a>
          <a href="https://opendatalab.com/Amphion/Emilia" target="_blank">
            <img src="https://img.shields.io/badge/OpenDataLab-Dataset-blue">
          </a>
          <a href="https://github.com/open-mmlab/Amphion/tree/main/preprocessors/Emilia" target="_blank">
            <img src="https://img.shields.io/badge/GitHub-Repo-green">
          </a>
          <a href="https://emilia-dataset.github.io/Emilia-Demo-Page/" target="_blank">
            <img src="https://img.shields.io/badge/WebPage-Demo-red">
          </a>
        </div> -->
        <div class="flex gap-2 justify-center flex-wrap">
          <a href="https://arxiv.org/abs/2411.06540" target="_blank">
            <img src="https://img.shields.io/badge/arXiv-Paper-COLOR.svg">
          </a>
          <a href="https://huggingface.co/datasets/amphion/Debatts-Data" target="_blank">
            <img src="https://img.shields.io/badge/%F0%9F%A4%97%20HuggingFace-Dataset-yellow"
              alt="Hugging Face Dataset">
          </a>
        </div>


        <div class="max-w-[900px] mx-auto mt-8 mb-16">
          <div class="text-center pb-10 flex flex-col gap-3">

          </div>
          <h5>Abstract</h5>
          <p class="text-p">
            In debating, rebuttal is one of the most critical stages, where a speaker addresses the arguments presented
            by the opposing side. During this process, the speaker synthesizes their own persuasive articulation given
            the context from the opposing side. This work proposes a novel zero-shot text-to-speech synthesis system for
            rebuttal, namely Debatts. Debatts takes two speech prompts, one from the opposing side (i.e. opponent) and
            one from the speaker. The prompt from the opponent is supposed to provide debating style prosody, and the
            prompt from the speaker provides identity information. In particular, we pretrain the Debatts system from
            in-the-wild dataset, and integrate an additional reference encoder to take debating prompt for style. In
            addition, we also create a debating dataset to develop Debatts. In this setting, Debatts can generate a
            debating-style speech in rebuttal for any voices. Experimental results confirm the effectiveness of the
            proposed system in comparison with the classic zero-shot TTS systems.
          </p>
        </div>

        <h4 id="dataset">The Debatts-Data Dataset</h4>

        <h5 id="dataset-overview">Overview</h5>
        <p class="text-p">
          The <code>Debatts-Data</code> dataset is constructed from a vast collection of professional Madarin speech
          data sourced from diverse
          video platforms and podcasts on the Internet. The in-the-wild collection approach ensures the real and natural
          rebuttal speech. This is the first Madarin rebuttal speech dataset for expressive text-to-speech synthesis.
          In addition, the dataset contains annotations of transcription, duration and style embed.
          The table and chart below provide the statistic information for the dataset.
        </p>

        <!-- <div class="my-4 grid grid-cols-1 mx-auto max-w-screen-sm md:grid-cols-2">
          <div class="relative overflow-x-auto mx-auto">
            <div class="relative w-fit text-sm text-left rtl:text-right text-gray-900 dark:text-gray-200">
              <div class="flex w-full text-center text-gray-900 bg-gray-50 dark:bg-gray-700 dark:text-gray-300">
                <div v-for="(item, index) in ['Lang.', 'Duration (hours)']" scope="col"
                  :class="(index == 0 ? 'w-[80px]' : 'w-[200px]') + ' shrink-0 px-6 py-4 font-bold'">
                  {{ item }}
                </div>
              </div>

              <div v-for="(item, index) in data"
                class="flex w-full text-center bg-white border-b dark:bg-gray-800 dark:border-gray-700 hover:bg-gray-50 dark:hover:bg-gray-600">
                <div v-for="(value, index) in Object.values(item)"
                  :class="(index == 0 ? 'w-[80px]' : 'w-[200px]') + ' px-4 py-2'">
                  {{ value.toLocaleString("en-US") }}
                </div>
              </div>
            </div>
          </div> -->
        <div class="my-4 overflow-x-auto mx-auto max-w-screen-md">
          <table class="w-full text-sm text-left text-gray-900 dark:text-gray-200">
            <caption class="text-center font-bold mb-4">
              Comparison of publicly Debate datasets.
            </caption>
            <thead class="bg-gray-50 dark:bg-gray-700">
              <tr>
                <th class="px-4 py-2 font-bold">Dataset</th>
                <th class="px-4 py-2 font-bold">Lang</th>
                <th class="px-4 py-2 font-bold">Num of Spks</th>
                <th class="px-4 py-2 font-bold">Duration(hrs)</th>
                <th class="px-4 py-2 font-bold">Text/Speech</th>
                <th class="px-4 py-2 font-bold">SR(kHz)</th>
                <th class="px-4 py-2 font-bold">Wild/Studio</th>
              </tr>
            </thead>
            <tbody>
              <tr class="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
                <td class="px-4 py-2">VivesDebate<sup>[1]</sup></td>
                <td class="px-4 py-2">EN</td>
                <td class="px-4 py-2">-</td>
                <td class="px-4 py-2">24 (est.)</td>
                <td class="px-4 py-2">T</td>
                <td class="px-4 py-2">-</td>
                <td class="px-4 py-2">W</td>
              </tr>
              <tr class="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
                <td class="px-4 py-2">Record<sup>[2]</sup></td>
                <td class="px-4 py-2">EN</td>
                <td class="px-4 py-2">10</td>
                <td class="px-4 py-2">6 (est.)</td>
                <td class="px-4 py-2">T+S</td>
                <td class="px-4 py-2">44.1</td>
                <td class="px-4 py-2">S</td>
              </tr>
              <tr class="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
                <td class="px-4 py-2">Rebuttal<sup>[3]</sup></td>
                <td class="px-4 py-2">EN</td>
                <td class="px-4 py-2">14</td>
                <td class="px-4 py-2">27 (est.)</td>
                <td class="px-4 py-2">T+S</td>
                <td class="px-4 py-2">-</td>
                <td class="px-4 py-2">S</td>
              </tr>
              <tr class="bg-white border-b dark:bg-gray-800 dark:border-gray-700">
                <td class="px-4 py-2">DBates<sup>[4]</sup></td>
                <td class="px-4 py-2">EN</td>
                <td class="px-4 py-2">140</td>
                <td class="px-4 py-2">70 (est.)</td>
                <td class="px-4 py-2">T+S</td>
                <td class="px-4 py-2">16</td>
                <td class="px-4 py-2">W</td>
              </tr>
              <tr class="bg-white border-b dark:bg-gray-800 dark:border-gray-700 font-bold">
                <td class="px-4 py-2">Debatts-Data</td>
                <td class="px-4 py-2">ZH</td>
                <td class="px-4 py-2">2350</td>
                <td class="px-4 py-2">111.9</td>
                <td class="px-4 py-2">T+S</td>
                <td class="px-4 py-2">16</td>
                <td class="px-4 py-2">W</td>
              </tr>
            </tbody>
          </table>
          <!-- 脚注部分 -->
          <!-- <div class="mt-4 text-sm text-gray-700 dark:text-gray-300">
              <p><strong>[1]</strong> Ruiz-Dolz, R., Nofre, M., Taulé, M., Heras, S., & García-Fornes, A. (2021). Vivesdebate: A new annotated multilingual corpus of argumentation in a debate tournament. <em>Applied Sciences</em>, 11(15), 7160.</p>
              <p><strong>[2]</strong> Mirkin, S., Jacovi, M., Lavee, T., Kuo, H. K., Thomas, S., Sager, L., ... & Slonim, N. (2017). A recorded debating dataset. <em>arXiv preprint arXiv:1709.06438</em>.</p>
              <p><strong>[3]</strong> Orbach, M., Bilu, Y., Gera, A., Kantor, Y., Dankin, L., Lavee, T., ... & Slonim, N. (2019). A dataset of general-purpose rebuttal. <em>arXiv preprint arXiv:1909.00393</em>.</p>
              <p><strong>[4]</strong> Sen, T. K., Naven, G., Gerstner, L., Bagley, D., Baten, R. A., Rahman, W., ... & Hoque, E. (2021). Dbates: Dataset for discerning benefits of audio, textual, and facial expression features in competitive debate speeches. <em>IEEE Transactions on Affective Computing</em>, 14(2), 1028-1043.</p>
            </div> -->
          <!-- 脚注部分 -->
          <div class="mt-4 text-sm text-gray-700 dark:text-gray-300">
            <p><strong>[1]</strong> Ruiz-Dolz, R., Nofre, M., Taulé, M., Heras, S., & García-Fornes, A. (2021).
              Vivesdebate: A new annotated multilingual corpus of argumentation in a debate
              tournament. <em>Applied Sciences</em>, 11(15), 7160.</p>
            <p><strong>[2]</strong> Mirkin, S., Jacovi, M., Lavee, T., Kuo, H. K., Thomas, S., Sager, L., ... & Slonim,
              N. (2017). A recorded debating dataset. <em>arXiv preprint arXiv:1709.06438</em>.</p>
            <p><strong>[3]</strong> Orbach, M., Bilu, Y., Gera, A., Kantor, Y., Dankin, L., Lavee, T., ... & Slonim, N.
              (2019). A dataset of general-purpose rebuttal. <em>arXiv preprint arXiv:1909.00393</em>.</p>
            <p><strong>[4]</strong> Sen, T. K., Naven, G., Gerstner, L., Bagley, D., Baten, R. A., Rahman, W., ... &
              Hoque, E. (2021). Dbates: Dataset for discerning benefits of audio, textual, and facial expression
              features in competitive debate speeches. <em>IEEE Transactions on Affective Computing</em>, 14(2),
              1028-1043.</p>
          </div>
        </div>



        <h5>Data Preview</h5>
        <p class="text-p">
          To better understand the performance of the pipeline as well as the diversity and quality of the rebuttal
          dataset, we
          have sampled a few speech examples below for preview. The below figure is an illustration of rebuttal.
        </p>
        <img class="mx-auto" src="./static/dataset_new_eample.svg" style="width: 35%; height: auto;">
        <br>
        <br>
        <h5>Sample Rebuttal Examples</h5>

        <div class="overflow-x-auto my-4">
          <table
            class="w-full text-sm text-left text-gray-900 dark:text-gray-200 border-collapse border border-gray-300 dark:border-gray-600">
            <thead class="bg-gray-100 dark:bg-gray-800">
              <tr>
                <th class="px-4 py-3 font-bold border border-gray-300 dark:border-gray-600 text-center">Rebuttal Subject
                </th>
                <th class="px-4 py-3 font-bold border border-gray-300 dark:border-gray-600 text-center">Opponent Speech
                </th>
                <th class="px-4 py-3 font-bold border border-gray-300 dark:border-gray-600 text-center">Speech</th>
              </tr>
            </thead>
            <tbody>
              <template v-for="(example, index) in data_preview_examples" :key="index">
                <tr class="bg-white dark:bg-gray-700">
                  <td class="px-4 py-3 text-center align-middle border border-gray-300 dark:border-gray-600"
                    :rowspan="Math.max((example.opponentSpeeches ? example.opponentSpeeches.length : 0), (example.speeches ? example.speeches.length : 0))">
                    <div>{{ example.subject }}</div>
                    <div class="text-gray-500 italic">{{ example.subject_translation }}</div>
                  </td>
                  <td class="px-4 py-3 align-top border border-gray-300 dark:border-gray-600">
                    <div v-if="example.opponentSpeeches && example.opponentSpeeches[0]">
                      <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
                        <source :src="example.opponentSpeeches[0].audio">
                      </audio>
                      <div>{{ example.opponentSpeeches[0].text }}</div>
                      <div class="text-gray-500 italic">{{ example.opponentSpeeches[0].translation }}</div>
                    </div>
                  </td>
                  <td class="px-4 py-3 align-top border border-gray-300 dark:border-gray-600">
                    <div v-if="example.speeches && example.speeches[0]">
                      <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
                        <source :src="example.speeches[0].audio">
                      </audio>
                      <div>{{ example.speeches[0].text }}</div>
                      <div class="text-gray-500 italic">{{ example.speeches[0].translation }}</div>
                    </div>
                  </td>
                </tr>
                <tr
                  v-for="i in (Math.max((example.opponentSpeeches ? example.opponentSpeeches.length : 0), (example.speeches ? example.speeches.length : 0)) - 1)"
                  :key="`${index}-${i}`" class="bg-white dark:bg-gray-700">
                  <td class="px-4 py-3 align-top border border-gray-300 dark:border-gray-600">
                    <div v-if="example.opponentSpeeches && example.opponentSpeeches[i]">
                      <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
                        <source :src="example.opponentSpeeches[i].audio">
                      </audio>
                      <div>{{ example.opponentSpeeches[i].text }}</div>
                      <div class="text-gray-500 italic">{{ example.opponentSpeeches[i].translation }}</div>
                    </div>
                  </td>
                  <td class="px-4 py-3 align-top border border-gray-300 dark:border-gray-600">
                    <div v-if="example.speeches && example.speeches[i]">
                      <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
                        <source :src="example.speeches[i].audio">
                      </audio>
                      <div>{{ example.speeches[i].text }}</div>
                      <div class="text-gray-500 italic">{{ example.speeches[i].translation }}</div>
                    </div>
                  </td>
                </tr>
              </template>
            </tbody>
          </table>
        </div>


      </div>

      <h4 id="pipeline">The Debatts-Data Preprocessing Pipeline</h4>
      <p class="text-p">
        <code>Debatts-Data Pipe</code> is the first open-source preprocessing pipeline designed to transform in-the-wild
        professional debating speech data into annotated, high-quality rebuttal data for text-to-speech generation.
        It encompasses five key steps: moderator detection, rebuttal session extraction, speaker diarization,
        overlap deletion, merging, and speech enhancement with metadata extraction.
        The diagram below outlines the Debatts-Data Pipe workflow. Initially, the pipeline introduces a precise
        methodology
        for detecting moderators within extensive competitive speech datasets, facilitating the extraction of relevant
        sections
        based on moderator cues. This approach is adaptable to other languages with minimal modifications and can be
        extended to any context involving moderator-led discussions.
      </p>
      <br>

      <!-- <div class="flex mx-auto justify-center max-w-screen-lg py-8">
          <img src="./static/emilia_pipe.svg"></img>
        </div> -->
      <img class="mx-auto" src="./static/dataset_pipeline_new.svg" style="width: 90%; height: auto;">

      <br>
      <p class="text-p">
        After processing, the Debatts-Data outputs the speech data in JSON and WAV format. The JSON file contains
        metadata such as language, transcription, style embedding and conversational context path, while the WAV file
        contains the speech data. The JSON file is
        structured as in the last step of pipeline.
      </p>

      <!-- <p class="text-p">
          The source code for Emilia-Pipe is available here: <a class="text-blue-500"
            href="https://github.com/open-mmlab/Amphion">open-mmlab/Amphion</a>.
        </p> -->

      <h4 id="model">The Debatts Model Architecture</h4>
      <p class="text-p">
        <code>Debatts</code> is the first zero-shot debating text-to-speech (TTS) system that utilizes the opponent's
        speech as a style prompt, alongside the target speaker's speech as a speaker identification prompt. It features
        a two-stage model architecture comprising a text-to-semantic stage and a semantic-to-acoustic stage. In the
        first stage, the model predicts target semantic tokens by integrating the semantic tokens from both the opponent
        and the target speaker, along with the text tokens. In the second stage, it generates speech with a debating
        style based on the concatenated target speaker's and predicted semantic tokens, combined with the target
        speaker's acoustic tokens. This approach enables the generation of natural and expressive rebuttal speech for
        any voice.
      </p>
      <img class="mx-auto" src="./static/model_architecture_new.svg" style="width: 90%; height: auto;">
      <br>
      <br>
      <h4 id="demos">Demos</h4>
      <p class="text-p">
        In this section, we demonstrate the zero-shot TTS performance of the Debatts compared to the baseline. Note that
        the translated text are just for illustration, and the generated speech are all in Madarin.
      </p>

      <h5 id="en-samples" class="text-lg font-semibold text-gray-900 dark:text-gray-100">Samples generated by Baseline
        Model and Debatts respectively,
        with speaker identification prompt from Debatts-Data.
      </h5>

      <!-- data_model_egs:table -->
      <!-- 标题部分 -->
      <div class="w-full overflow-x-auto my-4">
        <div class="relative w-full mx-auto text-sm text-left text-gray-900 dark:text-gray-100">
          <div
            class="grid grid-cols-4 text-center bg-gray-100 dark:bg-gray-800 border border-gray-300 dark:border-gray-600">
            <div v-for="(sound, idx) in data_model_egs_sounds" :key="sound.name"
              class="px-4 py-3 font-bold border-r border-gray-300 dark:border-gray-600 last:border-r-0">
              {{ sound.name }}
            </div>
          </div>
        </div>
      </div>

      <!-- 内容部分 -->
      <div v-for="(item, index) in data_model_egs" :key="index" class="my-4">
        <!-- 音频控件行 -->
        <div
          class="grid grid-cols-4 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 hover:bg-gray-50 dark:hover:bg-gray-600">
          <!-- 遍历所有音频控件 -->
          <div v-for="(sound, idx) in data_model_egs_sounds" :key="sound.name"
            class="px-4 py-3 text-center border-r border-gray-300 dark:border-gray-600 last:border-r-0">
            <!-- 音频控件 -->
            <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
              <source :src="'data/model_egs/' + item.path + '/' + sound.path">
            </audio>
          </div>
        </div>
        <!-- 对手文本与目标文本行 -->
        <div
          class="grid grid-cols-4 items-center mt-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600">
          <div class="col-span-1 px-4 py-3 border-r border-gray-300 dark:border-gray-600"></div>
          <!-- 对手文本 -->
          <div class="col-span-1 px-4 py-3 text-sm dark:text-gray-100 border-r border-gray-300 dark:border-gray-600">
            <div v-if="data_model_egs_sounds.some(sound => sound.path === 'oppo.wav')">
              <b>Opponent Text:</b> {{ item.opponentText }}
            </div>
          </div>
          <!-- 目标文本，跨越最后两个音频控件的宽度 -->
          <div class="col-span-2 px-4 py-3 text-left text-sm dark:text-gray-100">
            <div><b>Target Text:</b> {{ item.targetText }}</div>
            <div v-if="item.targetText_translated" class="text-gray-500 italic">
              <b class="italic">Translated Text:</b> {{ item.targetText_translated }}
            </div>
          </div>
        </div>
      </div>

      <br>
      <br>
      <h5 id="en-samples" class="text-lg font-semibold text-gray-900 dark:text-gray-100">
        Samples generated by Baseline Model and Debatts respectively with speaker identification prompt from Emilia
        Subset.
      </h5>

      <!-- data_model_emi_egs:table -->
      <!-- 标题部分 -->
      <div class="w-full overflow-x-auto my-4">
        <div class="relative w-full mx-auto text-sm text-left text-gray-900 dark:text-gray-100">
          <div
            class="grid grid-cols-4 text-center bg-gray-100 dark:bg-gray-800 border border-gray-300 dark:border-gray-600">
            <div v-for="(sound, idx) in data_model_emi_egs_sounds" :key="sound.name"
              class="px-4 py-3 font-bold border-r border-gray-300 dark:border-gray-600 last:border-r-0">
              {{ sound.name }}
            </div>
          </div>
        </div>
      </div>

      <!-- 内容部分 -->
      <div v-for="(item, index) in data_model_emi_egs" :key="index" class="my-4">
        <!-- 音频控件行 -->
        <div
          class="grid grid-cols-4 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600 hover:bg-gray-50 dark:hover:bg-gray-600">
          <!-- 遍历所有音频控件 -->
          <div v-for="(sound, idx) in data_model_emi_egs_sounds" :key="sound.name"
            class="px-4 py-3 text-center border-r border-gray-300 dark:border-gray-600 last:border-r-0">
            <!-- 音频控件 -->
            <audio controls class="w-full mb-2" controlsList="nodownload noremoteplayback">
              <source :src="'data/model_egs_emi/' + item.path + '/' + sound.path">
            </audio>
          </div>
        </div>
        <!-- 对手文本与目标文本行 -->
        <div
          class="grid grid-cols-4 items-center mt-2 bg-white dark:bg-gray-700 border border-gray-300 dark:border-gray-600">
          <div class="col-span-1 px-4 py-3 border-r border-gray-300 dark:border-gray-600"></div>
          <!-- 对手文本 -->
          <div class="col-span-1 px-4 py-3 text-sm dark:text-gray-100 border-r border-gray-300 dark:border-gray-600">
            <div v-if="data_model_emi_egs_sounds.some(sound => sound.path === 'oppo.wav')">
              <b>Opponent Text:</b> {{ item.opponentText }}
            </div>
          </div>

          <!-- 目标文本，跨越最后 2 个音频控件的宽度 -->
          <div class="col-span-2 px-4 py-3 text-left text-sm dark:text-gray-100">
            <div><b>Target Text:</b> {{ item.targetText }}</div>
            <div v-if="item.targetText_translated" class="text-gray-500 italic">
              <b class="italic">Translated Text:</b> {{ item.targetText_translated }}
            </div>
          </div>
        </div>
      </div>



      <section class="py-12">
        <h5 id="en-samples" class="text-lg font-semibold text-gray-900 dark:text-gray-100">
          Interactive Debating Video with Human
        </h5>
        <p class="text-p">
          This video is an example of Debatts’ synthesized speech interacting with a human voice, highlighting the SpeechLab's work at The Chinese University of Hong Kong, Shenzhen. The female voice is human, while the male voice is generated by Debatts, showcasing Debatts' natural, fluent, and highly expressive synthesized speech.
        </p>
        <!-- 直接用居中不行，显示不出来 -->
        <div class="center-text" style="display: flex; justify-content: center; text-align: center;">
          <video controls style="width: auto; height: 300px; " class="rounded-lg shadow-lg">
            <source src="./static/interactive.mp4" type="video/mp4">
            Your browser does not support the video tag.
          </video>
        </div>
      </section>


    </div>
  </div>

  </div>
  </div>
  </div>


  <script>
    const app = Vue.createApp({
      setup() {
        const data_preview_examples = [
          {
            subject: "熬夜是年轻人的病/药",
            subject_translation: "Staying up late is the young's dilemma or heal",
            opponentSpeeches: [
              {
                audio: "data/dataset_egs/eg_2/oppo_1.wav",
                text: "不要说夜晚，人一生所有的乐趣可能都是多巴胺的代偿，不要扣在夜头上，如果你说不能是跟朋友一起过，打电话叫朋友出来一起熬一起野一起嗨一起快乐，有很多的选择夜意味着选择夜只是个时间，不要用一个时间概念束缚了他所有分泌的方式，你承不承认？无论是个人还是群体都有找到自己快乐的方式，因为夜是属于自己自己的承认吗？",
                translation: "Don’t think that it’s only the joy of the night that comes as a dopamine reward; in reality, all the pleasures in life could be seen as a form of dopamine compensation. It’s not just the nighttime that brings such joy. If you say that you can't experience this with friends, you could always call them up, invite them out to enjoy the night together, and choose from a variety of activities. This means that choosing the night is merely about timing—don’t let a specific time define or limit how joy is experienced. Would you agree that because the night feels like a time that belongs entirely to oneself, it offers both individuals and groups the freedom to find their own sources of happiness?"
              },
              {
                audio: "data/dataset_egs/eg_2/oppo_2.wav",
                text: "夜才能找到为什么跟熬夜没关系。",
                translation: "Night is the time to find out the life meaning, why this healing effect has nothing to do with staying up late?"
              }
            ],
            speeches: [
              {
                audio: "data/dataset_egs/eg_2/speech_1.wav",
                text: "我方是，但是我觉得跟熬夜没关系，你方还是完全没有论证。",
                translation: "But I don't think having fun has anything to do with staying up late, and you still has no argument at all."
              },
              {
                audio: "data/dataset_egs/eg_2/speech_2.wav",
                text: "非常好，如果一个社会让我们只有夜是属于自己的，这还不是病吗？",
                translation: "Very good, so isn't it still a social dillemma if a society allows us to have only the night to ourselves?"
              }
            ]
          },
          {
            subject: "爱情和自由是成就徐志摩/阻碍徐志摩的人生价值",
            subject_translation: "Love and Freedom is slogan made or hindered Xu Zhimo's values in life",
            opponentSpeeches: [
              {
                audio: "data/dataset_egs/eg_1/oppo_1.wav",
                text: "对方辩友好。解释一下, 今天我方从来没有否认过徐志摩本人有所成就。但是我们今天一开始就跟你确认过了, 我们今天讨论是爱与自由, 到底给他在这些事情上面选择造成什么样的影响。所以刚才您方提出的包括时代推动文学等等, 我们已经要求您论证他与爱与自由文然关系。但是今天我方例子里面包括吸毒, 包括政治, 世界上各种不作为, 我们都已经论证过, 是爱与自由, 使他做出这样的负面行为。您方如何解释？",
                translation: "Let me explain, today we have never denied that Xu Zhimo had his own accomplishments. However, we have confirmed with you from the beginning of today's discussion that we are discussing love and freedom, and what kind of influence they had on his choices in these matters. Therefore, we have already asked you to prove his relationship with love and freedom, including the idea that the times drove literature. However, in our example today, including drug abuse, politics, and all kinds of inaction in the world, we have already argued that it is love and freedom that makes him do such negative behaviors. How do you explain the love for the country?"
              },
              {
                audio: "data/dataset_egs/eg_1/oppo_2.wav",
                text: "正面回应一下您这个例子。今天他在给泰戈尔秘书的回信里亲笔写道, 这是因为当时的时局由于当时的政府不配合以及贪官污吏的行为, 导致他的行径无法推进。今天咱们有一个史料上的对冲, 您不要跳点, 刚才我方已经给您论证了。他对家国的爱, 使他能够写出这样的诗篇, 进行到对当时起到一定社会贡献。由于他对爱与文学中爱与自由的这种向往, 所以他才会办以爱与自由。这种风格为出名的新月书店, 对当时有一个推动作用, 为什么跟爱与自由没关联？是不是时代贡献？",
                translation: "To respond directly to your example. Today he wrote in his own handwriting in his reply to Tagore's secretary that it was due to the prevailing circumstances that he was not able to move forward because of the lack of cooperation from the government of the day and the behavior of corrupt officials. Today we have a historical hedge, you do not jump the point, just now we have argued to you. His love for his family and country enabled him to write such poems and to make a social contribution to the society at that time. Because of his desire for love and freedom in love and literature, he organized the bookstore Love and Freedom, which was famous for its style. The Crescent Moon Bookstore, which was famous for its style, was a catalyst for the time, so why wasn't it related to love and freedom? Was it a contribution to the times?"
              }
            ],
            speeches: [
              {
                audio: "data/dataset_egs/eg_1/speech_1.wav",
                text: "对方辩友, 今天还是告诉我, 他先退了一步, 叫做医生开了药方, 徐志摩不知道这个药方用什么用, 徐志摩真的不知道吗？根据志摩日记记载, 徐志摩最知道陆小骗呃, 陆小曼吸食鸦片什么态度, 他是一个恼怒的态度, 而后转为无奈, 他只能继续攻势他。所以徐志摩明确知道陆小曼在做什么, 他在染毒液, 但他做了什么, 他还是供养他他作为当时那个可能是极少数知道鸦片会让中国人变成东亚病夫的人, 他还这样做, 他起到了怎样的一个表率。最后您方不看吗？",
                translation: "The other side of the defense, today or tell me, he first retreated, called as a doctor prescribed medicine, Xu Zhimo does not know this prescription with what use, Xu Zhimo really do not know? According to Zhimo diary records, Xu Zhimo most know Lu Xiaoliu cheat er, Lu Xiaoman smoking opium what attitude, he is an annoyed attitude, and then turned helpless, he can only continue to attack him. So Xu Zhimo clearly knew what Lu Xiaoman was doing, he was dyeing venom, but what he did, he still feed him him as the time that may be the very few people who knew that opium will make the Chinese people become the sick man of East Asia, he still do so, he played what a role model. Will your party not watch it at the end?"
              },
              {
                audio: "data/dataset_egs/eg_1/speech_2.wav",
                text: "不对, 对方辩友其实已经承认了嘛, 徐志摩是可以有很多其他多样化的价值的。而且对方辩友我们逼问了他很多次, 到底是不是徐志摩只有一条路可以走, 是不是他必须要成为他所说, 那种人才才算是成功的人, 不是他可以有其他的时代价值。所以对方辩友一退再退, 其实他只有一个点, 就是吸毒, 只有这一个点, 对不对？",
                translation: "You've actually already acknowledged that Xu Zhimo can have many other diverse values. We've asked you many times—does Xu Zhimo really have only one path he can take? Does he have to become a political talent to be considered a successful person? Can’t he have other values that resonate with the era? So, what you’re arguing is that his ideals of love and freedom hindered his ability to have broader societal impact, and your only point to support this is that Xu Zhimo's actions somehow condoned drug use, right?"
              }
            ]
          }
        ];

        const data_model_egs_sounds = [
          {
            name: "Speech Prompt",
            path: "spk.wav"
          },
          {
            name: "Opponent Prompt",
            path: "oppo.wav"
          },
          {
            name: "Baseline Model Generated",
            path: "ori.wav"
          },
          {
            name: "Debatts Generated",
            path: "new.wav"
          },
        ]

        const data_model_emi_egs_sounds = [
          {
            name: "Speech Prompt",
            path: "spk.wav"
          },
          {
            name: "Opponent Prompt",
            path: "oppo.wav"
          },
          {
            name: "Baseline Model Generated",
            path: "ori.wav"
          },
          {
            name: "Debatts Generated",
            path: "new.wav"
          },
        ]

        const data_model_emi_egs = [
          {
            path: "ss_57",
            targetText: "但不好意思打断一下, 我想继续问的是, 那在您方的这个定义之下, 除了我们能够去客观解释一些事情, 用科学的语言去解释。像我刚才也举例了, 说家里面设灵堂这些事情之外, 还有没有什么其他的表现？",
            targetText_translated: "Sorry to interrupt, but I’d like to continue my question. According to your definition, besides being able to objectively explain things using scientific language—as I mentioned earlier, like setting up a spirit hall at home—are there any other manifestations?",
            opponentText: "嗯, 首先上一件事情, 你方没有办法解决清楚的。嗯, 我们想着让孩子有的情感寄托, 是能让他们更好的去理解死亡分别的概念的。我们不希望让孩子觉得是因为死了, 他们的情感就是此断绝了。",
            oppotext_trans: "Well, first of all, there's something you haven't been able to clarify. We're trying to provide our children with emotional support so they can better understand the concept of death and separation. We don't want them to think that when someone dies, their emotional connections are completely cut off.",
          },
          {
            path: "ss_97",
            targetText: "来, 你知不知道在元宇宙存在很多伦理问题, 人格、隐私权侵犯问题以及数字殖民问题呢？",
            targetText_translated: "So, are you aware that the metaverse presents many ethical issues, such as violations of personal and privacy rights, as well as problems like digital colonization?",
            opponentText: "我方告诉你的是, 市场需求上, 我们刚才已经论证了, 它仍然是广阔的。我方认行的是元宇宙引领的这样一种数字化数字经济的这样一种方向, 是一个社会发展必然趋势。所以站在了政策的风口上, 您方跟我提出相抗, 我们不会往这种数字经济的方向呃呃碰有了脱实向虚。今天我方告诉你的是正式的一种虚拟化元宇宙会促进实体经济的增长。那那个market protex今年报告显示, 到二零二五年, 工业元宇宙收入将达到五千四百亿美元, 成为工业发展新引擎。最终是因为元宇宙有这样一种巨大拉动实体经济的这样一种引擎力。我们才会去发展它, 请问为什么不是我们的大势所趋？",
            oppotext_trans: "We have already demonstrated that there is still a vast market demand. We believe that a digital economy led by the metaverse is an inevitable trend for social development. So, we're aligning ourselves with policy trends. Your side opposes this, but we’re not going to move away from the digital economy direction or shift from the real to the virtual. Today, we’re telling you that a formal virtual metaverse will actually promote the growth of the real economy. According to Market Protex's report this year, by 2025, industrial metaverse revenue will reach $540 billion, becoming a new engine for industrial development. Ultimately, it’s because the metaverse has such a powerful drive for the real economy that we are developing it. So why isn't this our inevitable trend?",
          },
          {
            path: "ss_142",
            targetText: "啊, 前一些人类害怕的是传统战争大减少了回您方这个问题。所以我们发现科技发展史最近发展到现在, 人们最多最多, 担心的不过是所谓的自己的失误带来毁灭。但起码这个东西掌握在自己手里。",
            targetText_translated: "In rebuttal to your point, humans in the past primarily feared traditional wars, which have significantly decreased. So, we've found that with the recent advancements in technology, people's biggest concern is the potential for destruction caused by their own mistakes. But at least this is something they have control over.",
            opponentText: "在后续的论证中, 你方不能告诉我科学得出的一定是好的结论。使用科学的方法, 有可能出现中世纪研究的人道灾难, 当然也可能诞生七三幺部队这样的非法。",
            oppotext_trans: "In your subsequent arguments, you can't tell me that conclusions reached through science are necessarily good. Using scientific methods could lead to humanitarian disasters like those seen in medieval research, and of course, could also give rise to illegal actions like Unit 731.",
          },
          //   {
          //     path: "ss_170",
          //     targetText: "好, 第一个问题啊, 你方其实鼓励所有人都要做。那我再问你, 你方的态度到底是只要我在职场中遇到了任何不符合我的要求的事情, 我都需要出来反抗。对吗？",
          //     targetText_translated: "Alright, first of all, your side is actually encouraging everyone to do that. So let me ask you again: Is your position essentially that whenever I encounter something in the workplace that doesn't meet my expectations, I need to stand up against it? Is that correct?",
          //     opponentText: "您方的解决措施, 难道就是选择去服从酒桌文化, 选择去听从老板的PUA,而继续沉浸在这个恶臭的职场之中？",
          //     oppotext_trans: "Are your proposed solutions simply choosing to conform to the drinking culture, following the boss's brainwashing, and continuing to stay immersed in this toxic workplace?",
          //   },
          {
            path: "ss_183",
            targetText: "所以您方对于他解放出来, 这些时间不是去承接更多的案子, 而是去思考法律更深意义的论证。",
            targetText_translated: "So, by solving this problems, you will not choose to utilize this time to take on more cases but is instead focusing on exploring the deeper meanings of legal arguments, isn't it?",
            opponentText: "哦, 我方认为机遇是机会, 而挑战是可以给人们带来一定困难的。",
            oppotext_trans: "We believe that opportunities are somehow analogous to challenges, which may bring certain difficulties to people.",
          },
          {
            path: "ss_281",
            targetText: "所以对方辩友的立场已经跳动到他完全不反。",
            targetText_translated: "So you have shifted to them being completely non-oppositional.",
            opponentText: "对方辩友。所以在张桂梅这个例子, 当社会的宏观的这个社会机器鼓励着, 也要求着每个人努力的做自己本分的赚钱的事情的时候, 张桂梅觉得社会的这个稳定运行的机器说的不对, 她的感性自由驱使着他她要下到乡村中去帮助那些孩子。她在整个社会的宏宏观的视野里面, 他可能是沧海之一瞬一瞬间的火花。可是你觉得她美不美啊？",
            oppotext_trans: "In the example of Zhang Guimei, while the broader societal machine encourages and demands that everyone diligently do their part to earn money, Zhang Guimei feels that this stable social mechanism is flawed. Her emotional freedom drives her to go down to the countryside to help those children. From the perspective of the entire society, she might just be a fleeting spark in the vast ocean. But do you think her spirit is beautiful?",
          },
          {
            path: "ss_340",
            targetText: "懂了，所以你是说跟真相相反的观点就等于偏见。我今天来问你啊, 即便即便那个封建八孩当中的确是出现了人贩子。可是我的观点, 我的偏见是, 所有男生只要是农村, 先禁了妇女都是人贩子。这件事情是不是偏见？",
            targetText_translated: "So, are you saying that having a viewpoint that contradicts the truth is equivalent to prejudice? Today, I want to ask you: even though there are indeed human traffickers among the so-called 'feudal eight children,' my prejudice is that all boys from rural areas are human traffickers. Isn't this prejudice?",
            opponentText: "你们那些所有的例子, 就是恰恰是在大家广泛讨论之后, 我们得到一个破镜的真相, 有了盖棺定论。比如说现在俄乌冲突双方各执一词, 有的人说乌克兰就一定是坏人。有的人说, 俄罗斯就一定是坏人, 你怎么判断什么是偏见？",
            oppotext_trans: "All of your examples are exactly about how, after extensive discussions, we end up with a shattered truth and a final conclusion. For example, in the current Russia-Ukraine conflict, both sides stick to their own stories. Some people say Ukraine is definitely the bad guy. Others say Russia is definitely the bad guy. How do you determine what is prejudice?",
          },
        ]

        const data_model_egs = [
          {
            path: "ss_1",
            targetText_translated: "Please respond to this: his tendency to be imitated isn't because we value one side more, but rather due to the blind following effect of fans, which stems from their conformist mindset tied to their identity. Additionally, I'd like to ask: do you acknowledge that professional achievements have a public aspect, meaning they can be openly discussed by the public?",
            targetText: "嗯, 好的, 对方辩友来回应一下, 他要出现这个模仿, 不是因为我们更看重哪一个, 是因为粉丝的盲从效应好吧, 而这是他们身份的从众心理。那好, 对方辩友, 我想请问一下, 您是否承认专业成果具有公共性, 即可以拿出来被公众探讨这点, 您是否认同呢？",
            opponentText: "说了道德底线, 道德底线是违法犯罪, 在四至一的时候就已经跟你们确认过了。同时看一下今天的辩题是专业成果。作为一个医生, 他拿到的那个奖项是他的专业成果吗？",
            oppotext_trans: "",
          },
          {
            path: "ss_2",
            targetText_translated: "When explaining the part about anthocyanins to children, we simply say, 'Baby, see how the leaves are green when they grow on the tree and turn yellow before they fall off. This is the end of their life.' So, answer my question: why do you want to lead them down such a convoluted path, making them believe in the existence of heaven? What if the child wants to go to that heaven?",
            targetText: "给小孩讲花青素那个部分, 我们直接说, 宝宝, 你看那个树叶绿的时候长在树上黄了就掉下来, 这是生命的消失。所以你回答我的问题, 为什么呃, 您方要让他有那样曲径导向, 认为他有一个天堂的存在？如果小孩就想去那个天堂怎么办？",
            opponentText: "我觉得您方这个数据非常的扯淡, 是因为寻梦环游记一个关于死亡的故事。这么多人看是儿童的死亡率增呃就是增高了吗？或者是说我哪怕相信轮回, 我相信死亡可能是可以的。会让他立马去死吗？虔诚的基督教教徒和虔诚的佛教徒, 他们都去死了吗？",
            oppotext_trans: "",
          },
          //   {
          //     path: "ss_3",
          //     targetText_translated:"So today you’re telling us not to advocate for good science, yet all the examples you use to counter our arguments are unethical scientific cases like Unit 731. From your perspective, does our scientific development have to violate ethics in order to advance? Our scientific progress can address some security concerns, but that doesn't mean we aim to solve every problem, nor that all issues can only be resolved through science.",
          //     targetText: "所以今天对方辩友让我们不要论证好的科学, 但是您方给我方扣的帽子全都是七三幺部队, 这样没有人伦的科学。在您方看来, 我方科学的发展只能违背违背伦理才能发展, 是吧？我方科学要发展, 可以解决一部分安全感问题, 不代表我们要解决所有的问题, 不代表所有问题, 只能通过科学来解决",
          //     opponentText: "要效率的观点。我们来看有人在人工智能出现之后, 发现他远胜世界上的一切劳动, 这是科学在生产效率上的巨大突破。因此, 有人顺势就提出了无用阶级观念, 把这些人变成无用阶级, 用人工智能替代掉他们。这个时候, ChatGPT这类高强度人工智能的出现, 给社会带来了什么？",
          //     oppotext_trans:"",
          // },
          // {
          //   path: "ss_4",
          //   targetText_translated: "So what we've found is that if you misunderstand the spirit of a movement, you shouldn't reject the movement's fundamental rationale or its purpose. Instead, you should address the underlying issues.",
          //   targetText: "对所以我们发现, 如果你对一个运动的精神有错误的理解, 该否定的不是这项运动本身的合理性以及存在的意义。",
          //   opponentText: "我们没有不合理的原因是因为如果你在百度当中搜索整顿这个词条, 下面全都是。比如说包括教育整顿、金融秩序整顿等等, 由公权力自上而下的进行主动的、整体的解决问题式的整顿。而现在的媒体恰恰是用这种错误的方式来诠释整顿这件事情, 把原有的反抗全是为整顿。而这样的口号本身是错误的。我们不是指我们不是只在为自己的论点呃持放辩护。原因是因为比如说举了很多例子啊, 那如果我妈妈遇到了电信诈骗, 向公安部门举报, 这能够说我妈妈在着手整不是就是我们的论点。一的意思是现有的年轻人其实他挺稚嫩的, 他没有理解职场的正常的合理的规则, 盲目叫他们整顿, 可能会整顿错, 带来不可挽回的后果。",
          //   oppotext_trans: "",
          // },
          //   {
          //     path: "ss_5",
          //     targetText_translated:"All of your examples are precisely about how, after extensive discussions, we arrive at a fragmented truth and a final conclusion. For instance, in the current Russia-Ukraine conflict, both sides stick to their own narratives. Some people say Ukraine is definitely the wrong side. Others say Russia is definitely evils. How do you determine what is prejudice?",
          //     targetText: "你们那些所有的例子, 就是恰恰是在大家广泛讨论之后, 我们得到一个破镜的真相, 有了盖棺定论。比如说现在俄乌冲突双方各执一词, 有的人说乌克兰就一定是坏人。有的人说, 俄罗斯就一定是坏人, 你怎么判断什么是偏见？",
          //     opponentText: "嗯, 太好了, 对方辩友。你刚刚已经说到了, 就是即便是大概率这种表达方式, 也不应该有个体上升到群体。你也认可了, 在粉红色的女孩那件事情当中, 的确是有伤害的。而你方今天举的例子, 比如说李文亮印象, 他显然是基于自己的客观事实的。这个知医生知识的理解解是能够表达不能够扩散传播的。而是如果今天像美国说中国一定是恶意继出了这件事情, 这就是美国的偏见了。所以你看到没有？你的定义也很清楚。如果没有事实的检证, 就叫做偏见。我往下走, 我方刚刚反复问你了, 不管是这个上呃河南人的刻板印象, 还是是对于这个重庆女司c当中对男性女性互相的刻板印象叠加, 都没有得出最后之真相, 能不能告诉我在这些真相叠加继续被包容之后, 不会是进一步印象的加深, 而是你方说的回归理性的讨论。",
          //     oppotext_trans:"",
          //   },
        ]

        return {
          data_model_egs_sounds,
          data_model_emi_egs_sounds,
          data_model_egs,
          data_model_emi_egs,
          data_preview_examples,
        }
      }
    })

    app.mount('#app')
  </script>

</body>

</html>